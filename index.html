<!DOCTYPE html>
<html>
<body>

<h1>A study on speaker diarization limitations</h1>
<p>Speaker diarization is the process of labelling speech utterances in an audio signal with its corresponding speaker identity. Over the years, these systems have evolved with the goal of providing not only more robust outputs, but also to tackle issues such as intra-speaker variability and overlapping speech. Recently, researchers have incorporated ASR into these methods as a way to refine diarization outcomes. Nevertheless, current state-of-the-art systems are still prone to errors due to several disruptive factors, like the presence of noise and muffled speech.</p>
<p>The aim of this work consists of performing a comprehensive evaluation of the limitations of speaker diarization systems, to uncover aspects that hinder the accuracy of such methods. We assess 5 different open-source diarization pipelines -- which include diarization-only and joint ASR and diarization systems, such as pyannote and NeMo, respectively -- on their performance on a set of 10 heterogeneous benchmark data sets (e.g., AISHELL-4, VoxConverse). We conduct experiments to explore the impact of pre-training a pipeline on a larger and more varied data set, the effect of choosing different embedding and clustering models, and the influence of the speaker count as a hyper-parameter. We also compare the performance of joint pipelines against those of diarization-only systems, and analyse which audio characteristics highly impair speaker discrimination in these methods.</p>
<p>We show that a model pre-trained on a higher variety data set in an unsupervised scenario benefits most of the time, but this comes with over-labelling issues when there are few speakers and noisier audio. Our results also indicate that the choice of the embedding and clustering algorithms is not universal, as this is a data-dependent decision. We also reveal that, currently, diarization-only and joint approaches are very competitive in unsupervised scenarios, and that simpler architectures seem to benefit the most from providing the number of speakers. Lastly, we identify that short audio duration and low SNR still need to be tackled by such systems.</p>
<p>We propose using speech representation learning to further uncover underlying factors that affect diarization. Additional experiments on a larger set of pipelines are suggested to explore and compare unsupervised or supervised scenarios. Using pre-processing techniques to remove noise and performing hyper-parameter tuning are also recommended to further explore the outcomes of these systems.</p>

</body>
</html>